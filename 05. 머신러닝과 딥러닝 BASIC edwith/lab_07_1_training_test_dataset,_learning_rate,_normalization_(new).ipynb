{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab 07-1: training/test dataset, learning rate, normalization (new).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQQv1CDSf7B3",
        "outputId": "2637d750-86ed-4b7a-c03b-1e70056bc0b2"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJtDScdlgCu2"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "x_data = [[1, 2, 1],\n",
        "          [1, 3, 2],\n",
        "          [1, 3, 4],\n",
        "          [1, 5, 5],\n",
        "          [1, 7, 5],\n",
        "          [1, 2, 5],\n",
        "          [1, 6, 6],\n",
        "          [1, 7, 7]]\n",
        "y_data = [[0, 0, 1],\n",
        "          [0, 0, 1],\n",
        "          [0, 0, 1],\n",
        "          [0, 1, 0],\n",
        "          [0, 1, 0],\n",
        "          [0, 1, 0],\n",
        "          [1, 0, 0],\n",
        "          [1, 0, 0]]\n",
        "\n",
        "# Evaluation our model using this test dataset\n",
        "x_test = [[2, 1, 1],\n",
        "          [3, 1, 2],\n",
        "          [3, 3, 4]]\n",
        "y_test = [[0, 0, 1],\n",
        "          [0, 0, 1],\n",
        "          [0, 0, 1]]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJR--8eKgDta"
      },
      "source": [
        "X = tf.placeholder(\"float\", [None, 3])\n",
        "Y = tf.placeholder(\"float\", [None, 3])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 3]))\n",
        "b = tf.Variable(tf.random_normal([3]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wt0RyAhgS0M"
      },
      "source": [
        "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y* tf.log(hypothesis), axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr-ql4XxgS3X"
      },
      "source": [
        "prediction = tf.argmax(hypothesis, 1)\n",
        "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyPtgpzyglz4",
        "outputId": "aab3fb6f-280d-48cf-8e49-1966e70f8265"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(201):\n",
        "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
        "        print(step, cost_val, W_val)\n",
        "\n",
        "    # predict\n",
        "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
        "    # Calculate the accuracy\n",
        "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5.73203 [[ 0.7288166   0.71536213 -1.1801533 ]\n",
            " [-0.5775373  -0.1298833   1.6072978 ]\n",
            " [ 0.48373488 -0.51433605 -2.02127   ]]\n",
            "1 3.317995 [[ 0.6621908   0.7479632  -1.1461285 ]\n",
            " [-0.81948906  0.03000022  1.689366  ]\n",
            " [ 0.23214607 -0.33772916 -1.9462881 ]]\n",
            "2 2.0218027 [[ 0.6434202   0.74127686 -1.1206716 ]\n",
            " [-0.8116129  -0.00900118  1.7204912 ]\n",
            " [ 0.20866647 -0.3507957  -1.909742  ]]\n",
            "3 1.9710885 [[ 0.6235321   0.7400824  -1.099589  ]\n",
            " [-0.80967706 -0.01636278  1.725917  ]\n",
            " [ 0.17870611 -0.3366575  -1.8939198 ]]\n",
            "4 1.9446771 [[ 0.60733104  0.7366499  -1.0799555 ]\n",
            " [-0.79007834 -0.03363192  1.7235874 ]\n",
            " [ 0.16691464 -0.3340635  -1.8847224 ]]\n",
            "5 1.9235673 [[ 0.59031737  0.7351024  -1.0613943 ]\n",
            " [-0.77496755 -0.04048848  1.7153332 ]\n",
            " [ 0.15076596 -0.322094   -1.8805432 ]]\n",
            "6 1.9035922 [[ 0.57437915  0.7326286  -1.0429822 ]\n",
            " [-0.75527763 -0.05151999  1.7066748 ]\n",
            " [ 0.13977787 -0.31497923 -1.8766699 ]]\n",
            "7 1.88408 [[ 0.5581266   0.7307179  -1.024819  ]\n",
            " [-0.7377567  -0.05928205  1.696916  ]\n",
            " [ 0.12698433 -0.30518344 -1.8736721 ]]\n",
            "8 1.8649302 [[ 0.5422525   0.728469   -1.006696  ]\n",
            " [-0.71909696 -0.06834842  1.6873226 ]\n",
            " [ 0.11586066 -0.29726508 -1.8704668 ]]\n",
            "9 1.8461237 [[ 0.5263195   0.7263867  -0.9886808 ]\n",
            " [-0.70141983 -0.07617543  1.6774726 ]\n",
            " [ 0.10420263 -0.28866172 -1.8674121 ]]\n",
            "10 1.8276567 [[ 0.51057726  0.7241669  -0.97071874]\n",
            " [-0.68354446 -0.08428247  1.6677043 ]\n",
            " [ 0.09325794 -0.28090802 -1.8642211 ]]\n",
            "11 1.8095272 [[ 0.49487537  0.7219868  -0.9528367 ]\n",
            " [-0.66620725 -0.09177171  1.6578563 ]\n",
            " [ 0.08226088 -0.27309966 -1.8610324 ]]\n",
            "12 1.7917324 [[ 0.47930723  0.71973616 -0.9350179 ]\n",
            " [-0.6489746  -0.09918403  1.648036  ]\n",
            " [ 0.07167411 -0.26578876 -1.8577565 ]]\n",
            "13 1.774271 [[ 0.46381763  0.7174804  -0.9172725 ]\n",
            " [-0.6321231  -0.10618487  1.6381854 ]\n",
            " [ 0.06121072 -0.25863764 -1.8544443 ]]\n",
            "14 1.7571388 [[ 0.44844368  0.71517694 -0.89959514]\n",
            " [-0.61548597 -0.11297939  1.6283427 ]\n",
            " [ 0.05105056 -0.25185686 -1.8510649 ]]\n",
            "15 1.7403319 [[ 0.4331642   0.7128511  -0.88198984]\n",
            " [-0.5991741  -0.11943597  1.6184874 ]\n",
            " [ 0.04107855 -0.24531212 -1.8476377 ]]\n",
            "16 1.7238463 [[ 0.4179951   0.71048534 -0.864455  ]\n",
            " [-0.5831196  -0.12563755  1.6086345 ]\n",
            " [ 0.03136766 -0.23908745 -1.8441514 ]]\n",
            "17 1.7076764 [[ 0.40292796  0.70809    -0.84699255]\n",
            " [-0.56736916 -0.13153009  1.5987766 ]\n",
            " [ 0.02186806 -0.23312508 -1.8406141 ]]\n",
            "18 1.6918168 [[ 0.3879701   0.7056575  -0.8296022 ]\n",
            " [-0.5518933  -0.1371499   1.5889205 ]\n",
            " [ 0.01260979 -0.22745903 -1.8370218 ]]\n",
            "19 1.676261 [[ 0.3731181   0.7031923  -0.812285  ]\n",
            " [-0.5367118  -0.14247467  1.5790638 ]\n",
            " [ 0.00356907 -0.22206177 -1.8333783 ]]\n",
            "20 1.6610024 [[ 0.35837555  0.7006911  -0.79504126]\n",
            " [-0.52181023 -0.1475222   1.5692097 ]\n",
            " [-0.00524236 -0.21694614 -1.8296825 ]]\n",
            "21 1.6460342 [[ 0.34374106  0.6981562  -0.7778718 ]\n",
            " [-0.5071964  -0.15228415  1.5593579 ]\n",
            " [-0.01383764 -0.2120969  -1.8259364 ]]\n",
            "22 1.6313493 [[ 0.32921642  0.6955861  -0.760777  ]\n",
            " [-0.49286172 -0.15677103  1.5495101 ]\n",
            " [-0.02221327 -0.20751747 -1.8221402 ]]\n",
            "23 1.6169401 [[ 0.31480095  0.6929822  -0.7437576 ]\n",
            " [-0.4788082  -0.16098097  1.5396665 ]\n",
            " [-0.03037807 -0.20319754 -1.8182954 ]]\n",
            "24 1.6027992 [[ 0.30049556  0.6903441  -0.7268141 ]\n",
            " [-0.46502933 -0.16492175  1.5298284 ]\n",
            " [-0.03833249 -0.1991361  -1.8144023 ]]\n",
            "25 1.5889187 [[ 0.28629982  0.68767285 -0.7099471 ]\n",
            " [-0.45152393 -0.16859491  1.5199962 ]\n",
            " [-0.04608343 -0.19532493 -1.8104626 ]]\n",
            "26 1.5752913 [[ 0.27221408  0.68496865 -0.69315714]\n",
            " [-0.4382863  -0.17200714  1.5101708 ]\n",
            " [-0.05363354 -0.1917606  -1.8064768 ]]\n",
            "27 1.5619091 [[ 0.25823793  0.68223244 -0.67644477]\n",
            " [-0.4253133  -0.17516194  1.5003526 ]\n",
            " [-0.0609888  -0.18843587 -1.8024462 ]]\n",
            "28 1.5487646 [[ 0.24437132  0.6794648  -0.65981054]\n",
            " [-0.41259927 -0.17806567  1.4905423 ]\n",
            " [-0.06815299 -0.18534599 -1.7983719 ]]\n",
            "29 1.5358505 [[ 0.23061381  0.67666674 -0.64325494]\n",
            " [-0.40014    -0.18072303  1.4807404 ]\n",
            " [-0.07513175 -0.1824842  -1.7942549 ]]\n",
            "30 1.5231596 [[ 0.21696512  0.6738389  -0.6267784 ]\n",
            " [-0.38792974 -0.18314031  1.4709475 ]\n",
            " [-0.08192948 -0.17984505 -1.7900963 ]]\n",
            "31 1.5106846 [[ 0.2034247   0.6709825  -0.61038154]\n",
            " [-0.37596357 -0.18532288  1.4611639 ]\n",
            " [-0.0885516  -0.17742197 -1.7858973 ]]\n",
            "32 1.4984187 [[ 0.1899921   0.6680983  -0.5940647 ]\n",
            " [-0.3642357  -0.1872771   1.4513903 ]\n",
            " [-0.09500281 -0.17520922 -1.7816588 ]]\n",
            "33 1.4863548 [[ 0.17666666  0.66518736 -0.57782835]\n",
            " [-0.35274068 -0.18900877  1.4416269 ]\n",
            " [-0.10128834 -0.17320044 -1.777382  ]]\n",
            "34 1.4744871 [[ 0.16344775  0.66225076 -0.56167287]\n",
            " [-0.34147274 -0.19052415  1.4318744 ]\n",
            " [-0.10741311 -0.17138964 -1.7730681 ]]\n",
            "35 1.4628086 [[ 0.15033466  0.6592896  -0.5455986 ]\n",
            " [-0.33042625 -0.19182932  1.4221331 ]\n",
            " [-0.1133821  -0.16977073 -1.768718  ]]\n",
            "36 1.4513137 [[ 0.13732666  0.65630496 -0.529606  ]\n",
            " [-0.31959534 -0.19293049  1.4124033 ]\n",
            " [-0.11920016 -0.16833776 -1.7643329 ]]\n",
            "37 1.4399967 [[ 0.12442294  0.6532979  -0.51369524]\n",
            " [-0.3089744  -0.19383371  1.4026856 ]\n",
            " [-0.12487215 -0.16708472 -1.7599139 ]]\n",
            "38 1.4288521 [[ 0.11162269  0.65026957 -0.49786666]\n",
            " [-0.2985576  -0.1945452   1.3929803 ]\n",
            " [-0.13040276 -0.1660059  -1.7554622 ]]\n",
            "39 1.417874 [[ 0.09892502  0.6472211  -0.48212054]\n",
            " [-0.2883395  -0.19507094  1.383288  ]\n",
            " [-0.13579677 -0.16509548 -1.7509786 ]]\n",
            "40 1.407058 [[ 0.08632908  0.6441536  -0.4664571 ]\n",
            " [-0.27831435 -0.19541696  1.373609  ]\n",
            " [-0.14105864 -0.16434787 -1.7464644 ]]\n",
            "41 1.3963993 [[ 0.07383392  0.64106816 -0.45087653]\n",
            " [-0.26847675 -0.19558914  1.3639436 ]\n",
            " [-0.14619283 -0.16375755 -1.7419205 ]]\n",
            "42 1.3858931 [[ 0.06143862  0.637966   -0.43537903]\n",
            " [-0.25882125 -0.19559328  1.3542923 ]\n",
            " [-0.15120366 -0.16331911 -1.7373481 ]]\n",
            "43 1.375535 [[ 0.04914222  0.63484806 -0.4199647 ]\n",
            " [-0.24934264 -0.19543512  1.3446555 ]\n",
            " [-0.15609539 -0.1630273  -1.7327482 ]]\n",
            "44 1.3653208 [[ 0.03694374  0.63171554 -0.4046337 ]\n",
            " [-0.24003567 -0.19512032  1.3350338 ]\n",
            " [-0.16087204 -0.16287702 -1.7281218 ]]\n",
            "45 1.355247 [[ 0.02484218  0.6285695  -0.3893861 ]\n",
            " [-0.23089534 -0.19465426  1.3254274 ]\n",
            " [-0.16553764 -0.16286318 -1.72347   ]]\n",
            "46 1.3453095 [[ 0.01283655  0.625411   -0.37422195]\n",
            " [-0.2219167  -0.19404238  1.3158369 ]\n",
            " [-0.17009598 -0.16298094 -1.7187939 ]]\n",
            "47 1.3355048 [[ 9.2583749e-04  6.2224102e-01 -3.5914129e-01]\n",
            " [-2.1309499e-01 -1.9328991e-01  1.3062627e+00]\n",
            " [-1.7455080e-01 -1.6322553e-01 -1.7140944e+00]]\n",
            "48 1.3258293 [[-0.01089099  0.6190607  -0.34414414]\n",
            " [-0.20442554 -0.19240198  1.2967054 ]\n",
            " [-0.17890567 -0.16359237 -1.7093728 ]]\n",
            "49 1.3162805 [[-0.02261495  0.615871   -0.32923046]\n",
            " [-0.19590385 -0.19138353  1.2871653 ]\n",
            " [-0.18316406 -0.16407688 -1.7046299 ]]\n",
            "50 1.3068546 [[-0.03424707  0.6126729  -0.31440023]\n",
            " [-0.18752548 -0.1902395   1.2776428 ]\n",
            " [-0.18732926 -0.1646748  -1.6998668 ]]\n",
            "51 1.2975491 [[-0.0457884   0.6094674  -0.29965338]\n",
            " [-0.17928623 -0.18897457  1.2681386 ]\n",
            " [-0.19140452 -0.16538182 -1.6950845 ]]\n",
            "52 1.2883614 [[-0.05723996  0.6062554  -0.28498983]\n",
            " [-0.17118195 -0.18759337  1.2586532 ]\n",
            " [-0.19539289 -0.16619384 -1.690284  ]]\n",
            "53 1.2792885 [[-0.06860279  0.6030379  -0.27040946]\n",
            " [-0.16320868 -0.18610038  1.2491869 ]\n",
            " [-0.19929734 -0.16710688 -1.6854665 ]]\n",
            "54 1.2703285 [[-0.07987794  0.5998157  -0.25591215]\n",
            " [-0.15536258 -0.18449989  1.2397403 ]\n",
            " [-0.20312071 -0.16811702 -1.6806331 ]]\n",
            "55 1.2614784 [[-0.09106642  0.5965898  -0.24149773]\n",
            " [-0.14763992 -0.18279621  1.2303139 ]\n",
            " [-0.2068657  -0.16922057 -1.6757846 ]]\n",
            "56 1.2527363 [[-0.10216928  0.59336096 -0.22716604]\n",
            " [-0.14003716 -0.1809934   1.2209083 ]\n",
            " [-0.21053497 -0.17041379 -1.670922  ]]\n",
            "57 1.2441001 [[-0.11318754  0.5901301  -0.21291691]\n",
            " [-0.13255078 -0.1790954   1.2115239 ]\n",
            " [-0.21413095 -0.17169319 -1.6660466 ]]\n",
            "58 1.2355678 [[-0.12412222  0.58689797 -0.19875012]\n",
            " [-0.1251775  -0.17710614  1.2021613 ]\n",
            " [-0.2176561  -0.17305534 -1.6611593 ]]\n",
            "59 1.2271373 [[-0.13497433  0.58366543 -0.18466546]\n",
            " [-0.11791404 -0.17502935  1.192821  ]\n",
            " [-0.22111264 -0.17449689 -1.6562612 ]]\n",
            "60 1.2188069 [[-0.1457449   0.58043325 -0.17066269]\n",
            " [-0.11075738 -0.17286864  1.1835036 ]\n",
            " [-0.22450282 -0.1760146  -1.6513534 ]]\n",
            "61 1.210575 [[-0.15643492  0.57720214 -0.15674156]\n",
            " [-0.10370448 -0.17062758  1.1742097 ]\n",
            " [-0.22782867 -0.17760536 -1.6464367 ]]\n",
            "62 1.2024395 [[-0.16704538  0.5739729  -0.14290181]\n",
            " [-0.09675249 -0.16830951  1.1649396 ]\n",
            " [-0.2310922  -0.17926605 -1.6415125 ]]\n",
            "63 1.1943991 [[-0.17757729  0.5707461  -0.12914315]\n",
            " [-0.08989868 -0.16591786  1.1556941 ]\n",
            " [-0.23429534 -0.18099381 -1.6365817 ]]\n",
            "64 1.1864524 [[-0.1880316   0.5675226  -0.11546531]\n",
            " [-0.08314035 -0.16345578  1.1464738 ]\n",
            " [-0.23743989 -0.18278572 -1.6316452 ]]\n",
            "65 1.1785979 [[-0.1984093   0.564303   -0.101868  ]\n",
            " [-0.07647493 -0.16092639  1.1372789 ]\n",
            " [-0.24052754 -0.18463898 -1.6267043 ]]\n",
            "66 1.1708337 [[-0.20871136  0.5610879  -0.08835088]\n",
            " [-0.06990001 -0.15833277  1.1281104 ]\n",
            " [-0.24355999 -0.18655092 -1.62176   ]]\n",
            "67 1.1631591 [[-0.2189387   0.557878   -0.07491366]\n",
            " [-0.06341317 -0.15567778  1.1189686 ]\n",
            " [-0.24653876 -0.18851884 -1.6168133 ]]\n",
            "68 1.1555727 [[-0.22909227  0.55467397 -0.061556  ]\n",
            " [-0.05701216 -0.15296434  1.1098541 ]\n",
            " [-0.24946535 -0.19054024 -1.6118653 ]]\n",
            "69 1.1480732 [[-0.23917302  0.5514763  -0.04827757]\n",
            " [-0.05069481 -0.1501952   1.1007676 ]\n",
            " [-0.25234118 -0.19261262 -1.606917  ]]\n",
            "70 1.1406593 [[-0.24918187  0.5482856  -0.03507803]\n",
            " [-0.04445897 -0.14737302  1.0917096 ]\n",
            " [-0.25516757 -0.19473353 -1.6019697 ]]\n",
            "71 1.1333299 [[-0.25911972  0.5451024  -0.02195703]\n",
            " [-0.03830271 -0.1445004   1.0826807 ]\n",
            " [-0.2579459  -0.19690064 -1.5970243 ]]\n",
            "72 1.1260841 [[-0.26898745  0.54192734 -0.0089142 ]\n",
            " [-0.03222398 -0.14157997  1.0736816 ]\n",
            " [-0.26067722 -0.19911171 -1.5920819 ]]\n",
            "73 1.1189208 [[-0.27878597  0.53876084  0.00405079]\n",
            " [-0.02622101 -0.13861403  1.0647126 ]\n",
            " [-0.26336282 -0.2013644  -1.5871435 ]]\n",
            "74 1.111839 [[-0.28851616  0.53560346  0.01693833]\n",
            " [-0.02029195 -0.13560513  1.0557747 ]\n",
            " [-0.26600373 -0.20365667 -1.5822104 ]]\n",
            "75 1.1048379 [[-0.29817885  0.53245574  0.02974877]\n",
            " [-0.01443512 -0.13255545  1.0468682 ]\n",
            " [-0.26860097 -0.2059863  -1.5772835 ]]\n",
            "76 1.0979164 [[-0.3077749   0.5293181   0.04248249]\n",
            " [-0.0086488  -0.12946734  1.0379938 ]\n",
            " [-0.2711555  -0.20835133 -1.572364  ]]\n",
            "77 1.0910733 [[-0.31730518  0.526191    0.05513987]\n",
            " [-0.00293154 -0.12634294  1.0291522 ]\n",
            " [-0.27366838 -0.21074967 -1.5674528 ]]\n",
            "78 1.0843084 [[-0.32677048  0.5230749   0.06772127]\n",
            " [ 0.00271835 -0.12318439  1.0203438 ]\n",
            " [-0.2761403  -0.21317941 -1.5625511 ]]\n",
            "79 1.0776203 [[-0.33617166  0.5199703   0.08022708]\n",
            " [ 0.00830219 -0.11999375  1.0115693 ]\n",
            " [-0.27857223 -0.21563861 -1.55766   ]]\n",
            "80 1.0710086 [[-0.34550947  0.51687753  0.09265767]\n",
            " [ 0.0138215  -0.11677311  1.0028293 ]\n",
            " [-0.28096482 -0.21812549 -1.5527805 ]]\n",
            "81 1.0644724 [[-0.35478476  0.51379704  0.10501344]\n",
            " [ 0.01927748 -0.11352433  0.99412453]\n",
            " [-0.28331897 -0.22063816 -1.5479137 ]]\n",
            "82 1.0580108 [[-0.36399826  0.51072925  0.11729474]\n",
            " [ 0.02467158 -0.11024937  0.98545545]\n",
            " [-0.2856352  -0.2231749  -1.5430607 ]]\n",
            "83 1.0516235 [[-0.37315077  0.5076745   0.12950198]\n",
            " [ 0.03000492 -0.10695006  0.9768228 ]\n",
            " [-0.28791428 -0.22573394 -1.5382226 ]]\n",
            "84 1.0453093 [[-0.382243    0.5046332   0.14163554]\n",
            " [ 0.03527873 -0.10362823  0.96822715]\n",
            " [-0.29015678 -0.22831362 -1.5334003 ]]\n",
            "85 1.0390679 [[-0.39127573  0.5016057   0.15369578]\n",
            " [ 0.04049418 -0.10028563  0.9596691 ]\n",
            " [-0.29236326 -0.2309123  -1.5285951 ]]\n",
            "86 1.0328985 [[-0.4002497   0.49859232  0.16568309]\n",
            " [ 0.04565232 -0.09692399  0.95114934]\n",
            " [-0.2945343  -0.23352838 -1.523808  ]]\n",
            "87 1.0268005 [[-0.40916556  0.49559343  0.17759785]\n",
            " [ 0.0507542  -0.09354497  0.94266844]\n",
            " [-0.2966704  -0.23616028 -1.51904   ]]\n",
            "88 1.0207732 [[-0.41802406  0.49260935  0.18944043]\n",
            " [ 0.05580084 -0.09015019  0.934227  ]\n",
            " [-0.29877204 -0.23880647 -1.5142921 ]]\n",
            "89 1.0148159 [[-0.4268259   0.4896404   0.20121121]\n",
            " [ 0.06079319 -0.08674126  0.9258257 ]\n",
            " [-0.30083966 -0.24146548 -1.5095655 ]]\n",
            "90 1.0089284 [[-0.43557176  0.48668692  0.21291058]\n",
            " [ 0.06573219 -0.08331969  0.91746515]\n",
            " [-0.30287364 -0.2441358  -1.5048611 ]]\n",
            "91 1.0031098 [[-0.44426233  0.48374915  0.22453889]\n",
            " [ 0.07061869 -0.07988703  0.909146  ]\n",
            " [-0.30487442 -0.24681604 -1.5001801 ]]\n",
            "92 0.9973599 [[-0.4528982   0.48082742  0.23609653]\n",
            " [ 0.07545358 -0.07644472  0.90086883]\n",
            " [-0.30684233 -0.24950477 -1.4955235 ]]\n",
            "93 0.9916775 [[-0.46148008  0.477922    0.24758385]\n",
            " [ 0.08023761 -0.07299422  0.89263433]\n",
            " [-0.30877775 -0.25220066 -1.4908922 ]]\n",
            "94 0.9860627 [[-0.47000858  0.47503313  0.25900123]\n",
            " [ 0.08497161 -0.06953692  0.88444304]\n",
            " [-0.31068096 -0.25490236 -1.4862872 ]]\n",
            "95 0.9805147 [[-0.47848433  0.47216108  0.27034903]\n",
            " [ 0.0896563  -0.06607419  0.8762956 ]\n",
            " [-0.31255224 -0.2576086  -1.4817097 ]]\n",
            "96 0.97503316 [[-0.48690796  0.46930614  0.2816276 ]\n",
            " [ 0.0942924  -0.06260734  0.8681927 ]\n",
            " [-0.31439188 -0.26031804 -1.4771607 ]]\n",
            "97 0.9696175 [[-0.49528003  0.4664685   0.29283732]\n",
            " [ 0.09888057 -0.05913771  0.8601349 ]\n",
            " [-0.3162001  -0.26302952 -1.472641  ]]\n",
            "98 0.9642669 [[-0.50360113  0.46364844  0.30397853]\n",
            " [ 0.10342146 -0.05566652  0.85212284]\n",
            " [-0.3179772  -0.26574174 -1.4681517 ]]\n",
            "99 0.95898145 [[-0.5118719   0.46084616  0.3150516 ]\n",
            " [ 0.10791573 -0.05219504  0.8441571 ]\n",
            " [-0.3197233  -0.26845354 -1.4636937 ]]\n",
            "100 0.95376027 [[-0.52009284  0.45806187  0.32605684]\n",
            " [ 0.11236393 -0.0487245   0.8362383 ]\n",
            " [-0.32143867 -0.2711638  -1.4592681 ]]\n",
            "101 0.94860303 [[-0.5282646   0.45529583  0.33699462]\n",
            " [ 0.11676665 -0.04525602  0.8283671 ]\n",
            " [-0.32312346 -0.2738713  -1.4548758 ]]\n",
            "102 0.9435092 [[-0.5363876   0.4525482   0.34786528]\n",
            " [ 0.12112445 -0.04179082  0.8205441 ]\n",
            " [-0.3247778  -0.27657506 -1.4505178 ]]\n",
            "103 0.93847847 [[-0.5444625   0.4498192   0.3586692 ]\n",
            " [ 0.1254378  -0.03832998  0.81276995]\n",
            " [-0.32640195 -0.27927387 -1.4461948 ]]\n",
            "104 0.9335103 [[-0.55248976  0.447109    0.36940667]\n",
            " [ 0.12970729 -0.03487459  0.80504507]\n",
            " [-0.3279959  -0.28196675 -1.441908  ]]\n",
            "105 0.92860407 [[-0.5604699   0.4444178   0.38007805]\n",
            " [ 0.13393328 -0.03142574  0.79737025]\n",
            " [-0.3295599  -0.28465265 -1.4376581 ]]\n",
            "106 0.9237596 [[-0.5684035   0.44174576  0.39068368]\n",
            " [ 0.13811632 -0.02798446  0.7897459 ]\n",
            " [-0.33109397 -0.28733054 -1.433446  ]]\n",
            "107 0.9189763 [[-0.57629097  0.43909302  0.40122387]\n",
            " [ 0.1422568  -0.02455178  0.78217274]\n",
            " [-0.33259827 -0.28999949 -1.4292728 ]]\n",
            "108 0.91425365 [[-0.58413285  0.43645978  0.411699  ]\n",
            " [ 0.14635515 -0.0211287   0.7746513 ]\n",
            " [-0.33407286 -0.29265854 -1.4251391 ]]\n",
            "109 0.9095914 [[-0.5919296   0.4338462   0.42210934]\n",
            " [ 0.15041174 -0.01771615  0.7671821 ]\n",
            " [-0.33551788 -0.2953067  -1.4210459 ]]\n",
            "110 0.9049889 [[-0.59968174  0.4312524   0.43245524]\n",
            " [ 0.15442699 -0.01431512  0.7597658 ]\n",
            " [-0.33693334 -0.29794317 -1.416994  ]]\n",
            "111 0.90044594 [[-0.6073897   0.4286785   0.44273704]\n",
            " [ 0.15840125 -0.01092648  0.7524029 ]\n",
            " [-0.33831936 -0.30056697 -1.4129841 ]]\n",
            "112 0.8959618 [[-0.6150539   0.4261247   0.45295507]\n",
            " [ 0.16233489 -0.00755116  0.74509394]\n",
            " [-0.33967593 -0.30317733 -1.4090172 ]]\n",
            "113 0.89153624 [[-0.6226748   0.42359108  0.46310964]\n",
            " [ 0.16622816 -0.00418996  0.73783946]\n",
            " [-0.3410032  -0.30577332 -1.4050939 ]]\n",
            "114 0.88716865 [[-6.3025296e-01  4.2107776e-01  4.7320107e-01]\n",
            " [ 1.7008147e-01 -8.4383035e-04  7.3064005e-01]\n",
            " [-3.4230119e-01 -3.0835423e-01 -1.4012151e+00]]\n",
            "115 0.8828587 [[-0.6377887   0.41858488  0.48322967]\n",
            " [ 0.17389509  0.00248649  0.72349614]\n",
            " [-0.3435699  -0.31091923 -1.3973813 ]]\n",
            "116 0.87860584 [[-0.6452825   0.41611254  0.49319577]\n",
            " [ 0.1776693   0.00580018  0.71640825]\n",
            " [-0.34480944 -0.31346756 -1.3935934 ]]\n",
            "117 0.8744097 [[-0.6527347   0.41366082  0.5030997 ]\n",
            " [ 0.18140443  0.00909646  0.7093768 ]\n",
            " [-0.3460198  -0.3159985  -1.3898522 ]]\n",
            "118 0.8702699 [[-0.66014576  0.41122985  0.5129418 ]\n",
            " [ 0.18510072  0.01237457  0.7024024 ]\n",
            " [-0.34720105 -0.31851134 -1.3861581 ]]\n",
            "119 0.86618555 [[-0.6675161   0.40881968  0.5227223 ]\n",
            " [ 0.18875837  0.0156338   0.69548553]\n",
            " [-0.34835324 -0.32100537 -1.3825119 ]]\n",
            "120 0.8621567 [[-0.6748462   0.4064304   0.5324416 ]\n",
            " [ 0.19237776  0.01887342  0.6886265 ]\n",
            " [-0.34947634 -0.32347998 -1.3789141 ]]\n",
            "121 0.8581826 [[-0.6821363   0.4040621   0.5421    ]\n",
            " [ 0.19595905  0.02209279  0.6818259 ]\n",
            " [-0.35057044 -0.3259345  -1.3753655 ]]\n",
            "122 0.8542627 [[-0.68938684  0.40171483  0.55169785]\n",
            " [ 0.19950247  0.02529123  0.675084  ]\n",
            " [-0.35163558 -0.32836834 -1.3718666 ]]\n",
            "123 0.8503969 [[-0.69659823  0.3993887   0.56123537]\n",
            " [ 0.20300826  0.02846808  0.66840136]\n",
            " [-0.35267174 -0.3307809  -1.3684179 ]]\n",
            "124 0.8465842 [[-0.7037709   0.39708373  0.570713  ]\n",
            " [ 0.20647664  0.03162278  0.6617783 ]\n",
            " [-0.35367903 -0.3331716  -1.3650199 ]]\n",
            "125 0.84282446 [[-0.7109051   0.39479998  0.58013093]\n",
            " [ 0.20990784  0.03475469  0.65521514]\n",
            " [-0.3546574  -0.33553997 -1.3616732 ]]\n",
            "126 0.83911705 [[-0.71800125  0.39253747  0.5894896 ]\n",
            " [ 0.21330202  0.0378633   0.64871234]\n",
            " [-0.355607   -0.33788538 -1.3583783 ]]\n",
            "127 0.8354615 [[-0.7250597   0.39029628  0.5987893 ]\n",
            " [ 0.21665944  0.04094796  0.64227027]\n",
            " [-0.35652778 -0.34020746 -1.3551354 ]]\n",
            "128 0.8318572 [[-0.7320808   0.38807642  0.60803026]\n",
            " [ 0.21998027  0.04400828  0.6358891 ]\n",
            " [-0.35741982 -0.34250563 -1.3519453 ]]\n",
            "129 0.8283038 [[-0.739065    0.3858779   0.6172129 ]\n",
            " [ 0.22326472  0.04704366  0.6295693 ]\n",
            " [-0.35828313 -0.34477958 -1.348808  ]]\n",
            "130 0.82480067 [[-0.7460125   0.3837008   0.6263375 ]\n",
            " [ 0.22651292  0.05005372  0.62331104]\n",
            " [-0.35911784 -0.34702876 -1.3457241 ]]\n",
            "131 0.82134736 [[-0.7529237   0.38154507  0.63540447]\n",
            " [ 0.22972517  0.05303789  0.6171146 ]\n",
            " [-0.3599239  -0.34925288 -1.3426939 ]]\n",
            "132 0.8179431 [[-0.759799    0.37941077  0.64441407]\n",
            " [ 0.23290153  0.05599585  0.6109803 ]\n",
            " [-0.36070147 -0.35145152 -1.3397177 ]]\n",
            "133 0.81458765 [[-0.7666387   0.37729788  0.6533666 ]\n",
            " [ 0.23604225  0.0589271   0.6049083 ]\n",
            " [-0.36145058 -0.35362437 -1.3367958 ]]\n",
            "134 0.81128025 [[-0.7734431   0.37520638  0.6622625 ]\n",
            " [ 0.23914748  0.06183131  0.5988988 ]\n",
            " [-0.3621713  -0.3557711  -1.3339283 ]]\n",
            "135 0.8080204 [[-0.7802125   0.3731363   0.671102  ]\n",
            " [ 0.24221745  0.06470809  0.5929521 ]\n",
            " [-0.36286366 -0.35789138 -1.3311157 ]]\n",
            "136 0.80480766 [[-0.7869473   0.3710876   0.67988545]\n",
            " [ 0.24525227  0.06755713  0.5870682 ]\n",
            " [-0.36352783 -0.35998496 -1.3283579 ]]\n",
            "137 0.80164146 [[-0.79364777  0.36906028  0.68861324]\n",
            " [ 0.24825218  0.07037809  0.5812473 ]\n",
            " [-0.36416382 -0.3620516  -1.3256553 ]]\n",
            "138 0.798521 [[-0.80031425  0.3670543   0.69728565]\n",
            " [ 0.2512173   0.07317065  0.57548964]\n",
            " [-0.36477175 -0.3640911  -1.323008  ]]\n",
            "139 0.7954459 [[-0.806947    0.36506966  0.70590305]\n",
            " [ 0.2541479   0.07593457  0.56979513]\n",
            " [-0.3653517  -0.36610323 -1.3204159 ]]\n",
            "140 0.7924156 [[-0.8135464   0.36310628  0.71446586]\n",
            " [ 0.25704402  0.07866961  0.564164  ]\n",
            " [-0.36590382 -0.36808777 -1.3178792 ]]\n",
            "141 0.7894295 [[-0.82011276  0.36116415  0.7229743 ]\n",
            " [ 0.259906    0.08137546  0.55859613]\n",
            " [-0.36642814 -0.37004465 -1.315398  ]]\n",
            "142 0.786487 [[-0.8266463   0.3592432   0.7314288 ]\n",
            " [ 0.26273385  0.08405204  0.5530917 ]\n",
            " [-0.36692488 -0.37197363 -1.3129722 ]]\n",
            "143 0.78358734 [[-0.8331474   0.3573434   0.7398297 ]\n",
            " [ 0.2655279   0.08669902  0.54765064]\n",
            " [-0.36739406 -0.37387475 -1.3106018 ]]\n",
            "144 0.78073025 [[-0.83961636  0.3554647   0.74817735]\n",
            " [ 0.26828825  0.08931637  0.5422729 ]\n",
            " [-0.36783594 -0.37574777 -1.3082869 ]]\n",
            "145 0.7779148 [[-0.8460534   0.35360703  0.7564721 ]\n",
            " [ 0.27101517  0.09190382  0.5369586 ]\n",
            " [-0.36825052 -0.3775927  -1.3060274 ]]\n",
            "146 0.7751408 [[-0.85245895  0.3517703   0.7647143 ]\n",
            " [ 0.27370873  0.09446131  0.5317075 ]\n",
            " [-0.36863807 -0.3794095  -1.3038231 ]]\n",
            "147 0.7724074 [[-0.8588332   0.3499545   0.77290434]\n",
            " [ 0.2763692   0.09698869  0.52651966]\n",
            " [-0.36899862 -0.3811981  -1.3016739 ]]\n",
            "148 0.7697139 [[-0.86517644  0.3481595   0.7810426 ]\n",
            " [ 0.27899677  0.0994859   0.52139485]\n",
            " [-0.36933237 -0.38295853 -1.2995797 ]]\n",
            "149 0.7670599 [[-0.871489    0.34638524  0.7891294 ]\n",
            " [ 0.2815916   0.10195291  0.51633304]\n",
            " [-0.36963952 -0.38469076 -1.2975403 ]]\n",
            "150 0.7644447 [[-0.8777711   0.34463164  0.7971651 ]\n",
            " [ 0.2841539   0.10438963  0.511334  ]\n",
            " [-0.36992022 -0.38639486 -1.2955555 ]]\n",
            "151 0.7618678 [[-0.8840231   0.3428986   0.8051501 ]\n",
            " [ 0.28668395  0.10679601  0.50639755]\n",
            " [-0.37017462 -0.3880709  -1.293625  ]]\n",
            "152 0.7593285 [[-0.8902452   0.34118605  0.8130848 ]\n",
            " [ 0.28918186  0.10917213  0.50152355]\n",
            " [-0.37040296 -0.38971886 -1.2917486 ]]\n",
            "153 0.7568263 [[-0.89643776  0.33949387  0.8209695 ]\n",
            " [ 0.2916479   0.11151788  0.49671176]\n",
            " [-0.37060535 -0.39133894 -1.2899262 ]]\n",
            "154 0.75436044 [[-0.902601    0.33782196  0.8288047 ]\n",
            " [ 0.29408222  0.11383338  0.49196196]\n",
            " [-0.37078208 -0.39293116 -1.2881572 ]]\n",
            "155 0.7519305 [[-0.9087352   0.33617023  0.83659065]\n",
            " [ 0.2964851   0.1161186   0.48727387]\n",
            " [-0.37093326 -0.39449573 -1.2864414 ]]\n",
            "156 0.7495358 [[-0.9148407   0.33453858  0.8443278 ]\n",
            " [ 0.29885674  0.11837365  0.4826472 ]\n",
            " [-0.37105915 -0.3960327  -1.2847786 ]]\n",
            "157 0.7471757 [[-0.92091775  0.3329269   0.8520165 ]\n",
            " [ 0.30119732  0.12059858  0.47808167]\n",
            " [-0.37115997 -0.39754224 -1.2831682 ]]\n",
            "158 0.7448497 [[-0.92696655  0.33133504  0.85965717]\n",
            " [ 0.30350715  0.12279347  0.47357696]\n",
            " [-0.3712359  -0.39902458 -1.2816099 ]]\n",
            "159 0.7425573 [[-0.93298745  0.32976294  0.86725014]\n",
            " [ 0.30578637  0.12495849  0.46913272]\n",
            " [-0.37128723 -0.4004798  -1.2801033 ]]\n",
            "160 0.74029756 [[-0.93898064  0.3282104   0.87479585]\n",
            " [ 0.30803528  0.12709367  0.46474862]\n",
            " [-0.37131408 -0.4019082  -1.278648  ]]\n",
            "161 0.7380703 [[-0.94494647  0.32667738  0.8822947 ]\n",
            " [ 0.3102541   0.12919922  0.46042427]\n",
            " [-0.3713168  -0.4033099  -1.2772436 ]]\n",
            "162 0.73587483 [[-0.9508851   0.32516372  0.889747  ]\n",
            " [ 0.31244305  0.13127527  0.4561593 ]\n",
            " [-0.37129554 -0.4046852  -1.2758895 ]]\n",
            "163 0.7337104 [[-0.9567969   0.32366928  0.89715326]\n",
            " [ 0.31460238  0.13332196  0.45195326]\n",
            " [-0.37125057 -0.4060343  -1.2745854 ]]\n",
            "164 0.7315767 [[-0.96268207  0.32219395  0.9045138 ]\n",
            " [ 0.31673235  0.1353395   0.44780576]\n",
            " [-0.37118217 -0.4073574  -1.2733307 ]]\n",
            "165 0.729473 [[-0.96854085  0.3207376   0.91182894]\n",
            " [ 0.3188332   0.13732801  0.4437164 ]\n",
            " [-0.37109056 -0.40865484 -1.2721249 ]]\n",
            "166 0.72739875 [[-0.9743736   0.3193001   0.91909915]\n",
            " [ 0.32090515  0.13928778  0.4396847 ]\n",
            " [-0.37097603 -0.40992683 -1.2709675 ]]\n",
            "167 0.7253535 [[-0.98018044  0.31788126  0.92632484]\n",
            " [ 0.32294852  0.14121895  0.43571016]\n",
            " [-0.37083876 -0.4111737  -1.2698579 ]]\n",
            "168 0.7233366 [[-0.9859617   0.316481    0.93350637]\n",
            " [ 0.32496348  0.14312181  0.43179232]\n",
            " [-0.37067908 -0.41239566 -1.2687956 ]]\n",
            "169 0.7213475 [[-0.9917176   0.31509915  0.9406441 ]\n",
            " [ 0.3269504   0.14499651  0.42793068]\n",
            " [-0.3704972  -0.41359305 -1.2677801 ]]\n",
            "170 0.71938586 [[-0.9974484   0.31373557  0.94773847]\n",
            " [ 0.32890946  0.14684336  0.42412475]\n",
            " [-0.37029344 -0.41476616 -1.2668108 ]]\n",
            "171 0.71745086 [[-1.0031543   0.31239012  0.9547898 ]\n",
            " [ 0.33084095  0.14866257  0.42037404]\n",
            " [-0.37006804 -0.4159153  -1.265887  ]]\n",
            "172 0.7155423 [[-1.0088356   0.31106266  0.9617986 ]\n",
            " [ 0.33274513  0.15045445  0.41667798]\n",
            " [-0.36982128 -0.41704077 -1.2650083 ]]\n",
            "173 0.7136595 [[-1.0144925   0.30975303  0.9687652 ]\n",
            " [ 0.33462232  0.15221916  0.41303608]\n",
            " [-0.36955342 -0.41814294 -1.264174  ]]\n",
            "174 0.7118019 [[-1.0201254   0.3084611   0.97568995]\n",
            " [ 0.3364727   0.15395711  0.40944776]\n",
            " [-0.36926478 -0.41922203 -1.2633835 ]]\n",
            "175 0.7099691 [[-1.0257343   0.3071867   0.9825733 ]\n",
            " [ 0.33829662  0.15566845  0.4059125 ]\n",
            " [-0.36895555 -0.42027852 -1.2626363 ]]\n",
            "176 0.70816064 [[-1.0313196   0.3059297   0.9894155 ]\n",
            " [ 0.34009427  0.1573536   0.4024297 ]\n",
            " [-0.36862612 -0.4213126  -1.2619317 ]]\n",
            "177 0.70637596 [[-1.0368814   0.30468994  0.99621713]\n",
            " [ 0.34186605  0.1590127   0.39899883]\n",
            " [-0.36827663 -0.42232472 -1.261269  ]]\n",
            "178 0.70461464 [[-1.0424201   0.30346727  1.0029784 ]\n",
            " [ 0.34361207  0.16064622  0.39561927]\n",
            " [-0.36790752 -0.4233151  -1.2606477 ]]\n",
            "179 0.70287603 [[-1.0479358   0.30226153  1.0097    ]\n",
            " [ 0.34533283  0.16225427  0.39229047]\n",
            " [-0.3675189  -0.42428428 -1.2600671 ]]\n",
            "180 0.7011599 [[-1.0534289   0.3010726   1.0163819 ]\n",
            " [ 0.34702834  0.16383739  0.38901186]\n",
            " [-0.36711127 -0.42523235 -1.2595266 ]]\n",
            "181 0.69946575 [[-1.0588994   0.2999003   1.0230247 ]\n",
            " [ 0.34869918  0.16539562  0.3857828 ]\n",
            " [-0.36668462 -0.42615995 -1.2590257 ]]\n",
            "182 0.6977931 [[-1.0643476   0.29874447  1.0296288 ]\n",
            " [ 0.3503453   0.16692957  0.38260275]\n",
            " [-0.36623955 -0.42706713 -1.2585635 ]]\n",
            "183 0.6961416 [[-1.0697738   0.29760498  1.0361944 ]\n",
            " [ 0.3519673   0.1684393   0.37947103]\n",
            " [-0.36577603 -0.42795452 -1.2581396 ]]\n",
            "184 0.6945107 [[-1.0751781   0.29648167  1.0427221 ]\n",
            " [ 0.3535652   0.16992532  0.37638712]\n",
            " [-0.36529464 -0.42882225 -1.2577533 ]]\n",
            "185 0.69290006 [[-1.0805609   0.29537436  1.0492122 ]\n",
            " [ 0.35513946  0.17138779  0.37335038]\n",
            " [-0.3647954  -0.42967084 -1.2574039 ]]\n",
            "186 0.6913092 [[-1.0859224   0.29428294  1.055665  ]\n",
            " [ 0.35669026  0.17282718  0.3703602 ]\n",
            " [-0.36427876 -0.4305005  -1.2570908 ]]\n",
            "187 0.6897378 [[-1.0912626   0.29320723  1.062081  ]\n",
            " [ 0.35821792  0.1742437   0.367416  ]\n",
            " [-0.3637449  -0.43131173 -1.2568134 ]]\n",
            "188 0.68818545 [[-1.0965818   0.29214707  1.0684605 ]\n",
            " [ 0.35972273  0.17563777  0.36451712]\n",
            " [-0.36319417 -0.4321048  -1.256571  ]]\n",
            "189 0.6866517 [[-1.1018803   0.29110232  1.0748037 ]\n",
            " [ 0.3612049   0.1770097   0.361663  ]\n",
            " [-0.36262685 -0.43288    -1.2563632 ]]\n",
            "190 0.68513626 [[-1.1071583   0.29007283  1.0811112 ]\n",
            " [ 0.36266485  0.17835973  0.35885304]\n",
            " [-0.36204308 -0.4336379  -1.256189  ]]\n",
            "191 0.6836387 [[-1.112416    0.28905848  1.0873833 ]\n",
            " [ 0.3641027   0.17968838  0.35608658]\n",
            " [-0.36144334 -0.43437853 -1.2560481 ]]\n",
            "192 0.68215865 [[-1.1176536   0.28805906  1.0936203 ]\n",
            " [ 0.3655189   0.18099573  0.35336304]\n",
            " [-0.36082768 -0.43510258 -1.2559397 ]]\n",
            "193 0.68069583 [[-1.1228713   0.28707445  1.0998225 ]\n",
            " [ 0.3669135   0.18228237  0.35068178]\n",
            " [-0.36019662 -0.4358101  -1.2558633 ]]\n",
            "194 0.6792499 [[-1.1280692   0.28610447  1.1059904 ]\n",
            " [ 0.36828706  0.18354836  0.34804225]\n",
            " [-0.35955015 -0.43650168 -1.2558182 ]]\n",
            "195 0.6778203 [[-1.1332476   0.28514904  1.1121243 ]\n",
            " [ 0.36963955  0.18479432  0.34544381]\n",
            " [-0.35888883 -0.4371774  -1.2558038 ]]\n",
            "196 0.6764069 [[-1.1384068   0.28420794  1.1182245 ]\n",
            " [ 0.37097153  0.18602031  0.34288585]\n",
            " [-0.35821262 -0.43783784 -1.2558196 ]]\n",
            "197 0.67500937 [[-1.1435468   0.2832811   1.1242914 ]\n",
            " [ 0.372283    0.18722692  0.34036776]\n",
            " [-0.35752207 -0.4384831  -1.2558649 ]]\n",
            "198 0.6736274 [[-1.1486679   0.28236824  1.1303253 ]\n",
            " [ 0.37357458  0.18841413  0.337889  ]\n",
            " [-0.3568171  -0.43911383 -1.2559391 ]]\n",
            "199 0.67226064 [[-1.1537703   0.28146937  1.1363266 ]\n",
            " [ 0.3748461   0.18958266  0.33544892]\n",
            " [-0.35609838 -0.43972996 -1.2560418 ]]\n",
            "200 0.6709087 [[-1.1588541   0.28058425  1.1422955 ]\n",
            " [ 0.37609825  0.19073243  0.333047  ]\n",
            " [-0.35536578 -0.4403322  -1.2561721 ]]\n",
            "Prediction: [2 2 2]\n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_7QQe4qhuRw"
      },
      "source": [
        "# non-normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szZpue_9gyrg",
        "outputId": "2785cfbe-67d1-4e1d-9f6e-72776e97c19d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "\n",
        "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
        "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
        "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
        "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
        "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
        "               [819, 823, 1198100, 816, 820.450012],\n",
        "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
        "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
        "\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "# Hypothesis\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# Simplified cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(101):\n",
        "    cost_val, hy_val, _ = sess.run(\n",
        "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost:  2519695600000.0 \n",
            "Prediction:\n",
            " [[1120640. ]\n",
            " [2254801.8]\n",
            " [1774008. ]\n",
            " [1243902. ]\n",
            " [1465807.9]\n",
            " [1478132.2]\n",
            " [1354844.2]\n",
            " [1724677.4]]\n",
            "1 Cost:  2.7683404e+27 \n",
            "Prediction:\n",
            " [[-3.7114280e+13]\n",
            " [-7.4714848e+13]\n",
            " [-5.8775478e+13]\n",
            " [-4.1201298e+13]\n",
            " [-4.8557931e+13]\n",
            " [-4.8966637e+13]\n",
            " [-4.4879615e+13]\n",
            " [-5.7140673e+13]]\n",
            "2 Cost:  inf \n",
            "Prediction:\n",
            " [[1.2302029e+21]\n",
            " [2.4765244e+21]\n",
            " [1.9481925e+21]\n",
            " [1.3656725e+21]\n",
            " [1.6095181e+21]\n",
            " [1.6230651e+21]\n",
            " [1.4875953e+21]\n",
            " [1.8940044e+21]]\n",
            "3 Cost:  inf \n",
            "Prediction:\n",
            " [[-4.0776728e+28]\n",
            " [-8.2087735e+28]\n",
            " [-6.4575462e+28]\n",
            " [-4.5267056e+28]\n",
            " [-5.3349646e+28]\n",
            " [-5.3798677e+28]\n",
            " [-4.9308349e+28]\n",
            " [-6.2779334e+28]]\n",
            "4 Cost:  inf \n",
            "Prediction:\n",
            " [[1.3515997e+36]\n",
            " [2.7209087e+36]\n",
            " [2.1404409e+36]\n",
            " [1.5004377e+36]\n",
            " [1.7683460e+36]\n",
            " [1.7832298e+36]\n",
            " [1.6343917e+36]\n",
            " [2.0809057e+36]]\n",
            "5 Cost:  inf \n",
            "Prediction:\n",
            " [[-inf]\n",
            " [-inf]\n",
            " [-inf]\n",
            " [-inf]\n",
            " [-inf]\n",
            " [-inf]\n",
            " [-inf]\n",
            " [-inf]]\n",
            "6 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "7 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "8 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "9 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "10 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "11 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "12 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "13 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "14 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "15 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "16 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "17 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "18 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "19 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "20 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "21 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "22 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "23 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "24 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "25 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "26 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "27 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "28 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "29 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "30 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "31 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "32 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "33 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "34 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "35 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "36 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "37 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "38 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "39 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "40 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "41 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "42 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "43 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "44 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "45 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "46 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "47 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "48 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "49 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "50 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "51 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "52 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "53 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "54 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "55 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "56 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "57 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "58 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "59 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "60 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "61 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "62 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "63 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "64 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "65 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "66 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "67 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "68 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "69 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "70 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "71 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "72 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "73 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "74 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "75 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "76 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "77 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "78 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "79 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "80 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "81 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "82 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "83 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "84 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "85 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "86 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "87 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "88 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "89 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "90 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "91 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "92 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "93 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "94 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "95 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "96 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "97 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "98 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "99 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n",
            "100 Cost:  nan \n",
            "Prediction:\n",
            " [[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykXJGt-hhxYo",
        "outputId": "e2212341-bad9-4161-ad89-7c8ed0026824"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "\n",
        "def min_max_scaler(data):\n",
        "    numerator = data - np.min(data, 0)\n",
        "    denominator = np.max(data, 0) - np.min(data, 0)\n",
        "    # noise term prevents the zero division\n",
        "    return numerator / (denominator + 1e-7)\n",
        "\n",
        "\n",
        "xy = np.array(\n",
        "    [\n",
        "        [828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
        "        [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
        "        [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
        "        [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
        "        [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
        "        [819, 823, 1198100, 816, 820.450012],\n",
        "        [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
        "        [809.51001, 816.659973, 1398100, 804.539978, 809.559998],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# very important. It does not work without it.\n",
        "xy = min_max_scaler(xy)\n",
        "print(xy)\n",
        "\n",
        "'''\n",
        "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
        " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
        " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
        " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
        " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
        " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
        " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
        " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
        "'''\n",
        "\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "# Hypothesis\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# Simplified cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "with tf.Session() as sess:\n",
        "    # Initializes global variables in the graph.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(101):\n",
        "        _, cost_val, hy_val = sess.run(\n",
        "            [train, cost, hypothesis], feed_dict={X: x_data, Y: y_data}\n",
        "        )\n",
        "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
            " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
            " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
            " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
            " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
            " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
            " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
            " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
            "0 Cost:  6.008363 \n",
            "Prediction:\n",
            " [[-2.787303  ]\n",
            " [-2.3049731 ]\n",
            " [-1.9524162 ]\n",
            " [-1.5445647 ]\n",
            " [-1.8520749 ]\n",
            " [-1.818827  ]\n",
            " [-1.0787338 ]\n",
            " [-0.97747326]]\n",
            "1 Cost:  6.0079103 \n",
            "Prediction:\n",
            " [[-2.7871776 ]\n",
            " [-2.304853  ]\n",
            " [-1.9523162 ]\n",
            " [-1.5444872 ]\n",
            " [-1.8519831 ]\n",
            " [-1.8187385 ]\n",
            " [-1.078675  ]\n",
            " [-0.97741604]]\n",
            "2 Cost:  6.007457 \n",
            "Prediction:\n",
            " [[-2.7870522]\n",
            " [-2.3047333]\n",
            " [-1.9522161]\n",
            " [-1.5444096]\n",
            " [-1.851891 ]\n",
            " [-1.8186496]\n",
            " [-1.0786163]\n",
            " [-0.9773588]]\n",
            "3 Cost:  6.007004 \n",
            "Prediction:\n",
            " [[-2.786927 ]\n",
            " [-2.304613 ]\n",
            " [-1.9521161]\n",
            " [-1.5443321]\n",
            " [-1.8517992]\n",
            " [-1.8185611]\n",
            " [-1.0785575]\n",
            " [-0.9773016]]\n",
            "4 Cost:  6.0065513 \n",
            "Prediction:\n",
            " [[-2.7868018]\n",
            " [-2.304493 ]\n",
            " [-1.9520161]\n",
            " [-1.5442547]\n",
            " [-1.8517072]\n",
            " [-1.8184723]\n",
            " [-1.0784987]\n",
            " [-0.9772444]]\n",
            "5 Cost:  6.006099 \n",
            "Prediction:\n",
            " [[-2.7866764]\n",
            " [-2.3043733]\n",
            " [-1.9519161]\n",
            " [-1.544177 ]\n",
            " [-1.8516154]\n",
            " [-1.8183837]\n",
            " [-1.07844  ]\n",
            " [-0.9771871]]\n",
            "6 Cost:  6.0056467 \n",
            "Prediction:\n",
            " [[-2.786551 ]\n",
            " [-2.3042533]\n",
            " [-1.9518161]\n",
            " [-1.5440996]\n",
            " [-1.8515235]\n",
            " [-1.8182949]\n",
            " [-1.0783813]\n",
            " [-0.9771299]]\n",
            "7 Cost:  6.0051937 \n",
            "Prediction:\n",
            " [[-2.7864256 ]\n",
            " [-2.3041334 ]\n",
            " [-1.9517161 ]\n",
            " [-1.5440221 ]\n",
            " [-1.8514316 ]\n",
            " [-1.8182063 ]\n",
            " [-1.0783225 ]\n",
            " [-0.97707266]]\n",
            "8 Cost:  6.004741 \n",
            "Prediction:\n",
            " [[-2.7863004 ]\n",
            " [-2.3040135 ]\n",
            " [-1.951616  ]\n",
            " [-1.5439446 ]\n",
            " [-1.8513397 ]\n",
            " [-1.8181176 ]\n",
            " [-1.0782638 ]\n",
            " [-0.97701544]]\n",
            "9 Cost:  6.004288 \n",
            "Prediction:\n",
            " [[-2.7861753 ]\n",
            " [-2.3038936 ]\n",
            " [-1.951516  ]\n",
            " [-1.5438671 ]\n",
            " [-1.8512478 ]\n",
            " [-1.8180289 ]\n",
            " [-1.078205  ]\n",
            " [-0.97695816]]\n",
            "10 Cost:  6.0038357 \n",
            "Prediction:\n",
            " [[-2.7860498 ]\n",
            " [-2.3037734 ]\n",
            " [-1.951416  ]\n",
            " [-1.5437896 ]\n",
            " [-1.8511558 ]\n",
            " [-1.8179402 ]\n",
            " [-1.0781462 ]\n",
            " [-0.97690094]]\n",
            "11 Cost:  6.0033827 \n",
            "Prediction:\n",
            " [[-2.7859244]\n",
            " [-2.3036537]\n",
            " [-1.951316 ]\n",
            " [-1.543712 ]\n",
            " [-1.851064 ]\n",
            " [-1.8178515]\n",
            " [-1.0780874]\n",
            " [-0.9768437]]\n",
            "12 Cost:  6.0029306 \n",
            "Prediction:\n",
            " [[-2.785799 ]\n",
            " [-2.3035336]\n",
            " [-1.9512161]\n",
            " [-1.5436347]\n",
            " [-1.850972 ]\n",
            " [-1.8177629]\n",
            " [-1.0780287]\n",
            " [-0.9767865]]\n",
            "13 Cost:  6.002478 \n",
            "Prediction:\n",
            " [[-2.7856739]\n",
            " [-2.3034139]\n",
            " [-1.951116 ]\n",
            " [-1.543557 ]\n",
            " [-1.8508801]\n",
            " [-1.8176742]\n",
            " [-1.07797  ]\n",
            " [-0.9767293]]\n",
            "14 Cost:  6.0020256 \n",
            "Prediction:\n",
            " [[-2.7855487 ]\n",
            " [-2.3032937 ]\n",
            " [-1.9510161 ]\n",
            " [-1.5434796 ]\n",
            " [-1.8507884 ]\n",
            " [-1.8175855 ]\n",
            " [-1.0779113 ]\n",
            " [-0.97667205]]\n",
            "15 Cost:  6.0015736 \n",
            "Prediction:\n",
            " [[-2.7854233]\n",
            " [-2.303174 ]\n",
            " [-1.950916 ]\n",
            " [-1.543402 ]\n",
            " [-1.8506963]\n",
            " [-1.8174968]\n",
            " [-1.0778525]\n",
            " [-0.9766148]]\n",
            "16 Cost:  6.0011206 \n",
            "Prediction:\n",
            " [[-2.7852979 ]\n",
            " [-2.3030539 ]\n",
            " [-1.950816  ]\n",
            " [-1.5433245 ]\n",
            " [-1.8506044 ]\n",
            " [-1.8174081 ]\n",
            " [-1.0777937 ]\n",
            " [-0.97655755]]\n",
            "17 Cost:  6.0006685 \n",
            "Prediction:\n",
            " [[-2.7851727]\n",
            " [-2.302934 ]\n",
            " [-1.950716 ]\n",
            " [-1.5432471]\n",
            " [-1.8505126]\n",
            " [-1.8173195]\n",
            " [-1.0777351]\n",
            " [-0.9765004]]\n",
            "18 Cost:  6.0002165 \n",
            "Prediction:\n",
            " [[-2.7850475 ]\n",
            " [-2.3028142 ]\n",
            " [-1.9506162 ]\n",
            " [-1.5431696 ]\n",
            " [-1.8504207 ]\n",
            " [-1.8172309 ]\n",
            " [-1.0776763 ]\n",
            " [-0.97644323]]\n",
            "19 Cost:  5.999764 \n",
            "Prediction:\n",
            " [[-2.7849221]\n",
            " [-2.3026943]\n",
            " [-1.9505162]\n",
            " [-1.5430923]\n",
            " [-1.8503289]\n",
            " [-1.8171422]\n",
            " [-1.0776176]\n",
            " [-0.9763861]]\n",
            "20 Cost:  5.999312 \n",
            "Prediction:\n",
            " [[-2.784797  ]\n",
            " [-2.3025746 ]\n",
            " [-1.9504163 ]\n",
            " [-1.5430148 ]\n",
            " [-1.8502371 ]\n",
            " [-1.8170537 ]\n",
            " [-1.077559  ]\n",
            " [-0.97632885]]\n",
            "21 Cost:  5.9988604 \n",
            "Prediction:\n",
            " [[-2.7846718]\n",
            " [-2.3024547]\n",
            " [-1.9503164]\n",
            " [-1.5429373]\n",
            " [-1.8501452]\n",
            " [-1.8169651]\n",
            " [-1.0775002]\n",
            " [-0.9762717]]\n",
            "22 Cost:  5.9984074 \n",
            "Prediction:\n",
            " [[-2.7845464]\n",
            " [-2.3023348]\n",
            " [-1.9502164]\n",
            " [-1.5428599]\n",
            " [-1.8500533]\n",
            " [-1.8168764]\n",
            " [-1.0774416]\n",
            " [-0.9762145]]\n",
            "23 Cost:  5.997956 \n",
            "Prediction:\n",
            " [[-2.7844212 ]\n",
            " [-2.302215  ]\n",
            " [-1.9501164 ]\n",
            " [-1.5427824 ]\n",
            " [-1.8499615 ]\n",
            " [-1.8167878 ]\n",
            " [-1.0773829 ]\n",
            " [-0.97615737]]\n",
            "24 Cost:  5.997504 \n",
            "Prediction:\n",
            " [[-2.784296 ]\n",
            " [-2.3020952]\n",
            " [-1.9500166]\n",
            " [-1.542705 ]\n",
            " [-1.8498697]\n",
            " [-1.8166993]\n",
            " [-1.0773242]\n",
            " [-0.9761002]]\n",
            "25 Cost:  5.997052 \n",
            "Prediction:\n",
            " [[-2.7841709 ]\n",
            " [-2.3019755 ]\n",
            " [-1.9499166 ]\n",
            " [-1.5426276 ]\n",
            " [-1.8497779 ]\n",
            " [-1.8166106 ]\n",
            " [-1.0772655 ]\n",
            " [-0.97604305]]\n",
            "26 Cost:  5.9965997 \n",
            "Prediction:\n",
            " [[-2.7840457]\n",
            " [-2.3018553]\n",
            " [-1.9498167]\n",
            " [-1.5425501]\n",
            " [-1.8496861]\n",
            " [-1.816522 ]\n",
            " [-1.0772069]\n",
            " [-0.9759859]]\n",
            "27 Cost:  5.9961476 \n",
            "Prediction:\n",
            " [[-2.7839203]\n",
            " [-2.3017354]\n",
            " [-1.9497168]\n",
            " [-1.5424726]\n",
            " [-1.8495942]\n",
            " [-1.8164334]\n",
            " [-1.0771482]\n",
            " [-0.9759287]]\n",
            "28 Cost:  5.995695 \n",
            "Prediction:\n",
            " [[-2.7837949 ]\n",
            " [-2.3016157 ]\n",
            " [-1.9496168 ]\n",
            " [-1.5423952 ]\n",
            " [-1.8495024 ]\n",
            " [-1.8163447 ]\n",
            " [-1.0770894 ]\n",
            " [-0.97587156]]\n",
            "29 Cost:  5.995244 \n",
            "Prediction:\n",
            " [[-2.7836697]\n",
            " [-2.3014958]\n",
            " [-1.9495168]\n",
            " [-1.5423179]\n",
            " [-1.8494105]\n",
            " [-1.8162562]\n",
            " [-1.0770308]\n",
            " [-0.9758144]]\n",
            "30 Cost:  5.994792 \n",
            "Prediction:\n",
            " [[-2.7835445 ]\n",
            " [-2.3013759 ]\n",
            " [-1.949417  ]\n",
            " [-1.5422404 ]\n",
            " [-1.8493187 ]\n",
            " [-1.8161676 ]\n",
            " [-1.0769721 ]\n",
            " [-0.97575724]]\n",
            "31 Cost:  5.99434 \n",
            "Prediction:\n",
            " [[-2.7834194]\n",
            " [-2.3012562]\n",
            " [-1.949317 ]\n",
            " [-1.5421629]\n",
            " [-1.849227 ]\n",
            " [-1.8160789]\n",
            " [-1.0769134]\n",
            " [-0.9757   ]]\n",
            "32 Cost:  5.9938884 \n",
            "Prediction:\n",
            " [[-2.7832942 ]\n",
            " [-2.3011365 ]\n",
            " [-1.9492171 ]\n",
            " [-1.5420854 ]\n",
            " [-1.8491352 ]\n",
            " [-1.8159904 ]\n",
            " [-1.0768547 ]\n",
            " [-0.97564286]]\n",
            "33 Cost:  5.993436 \n",
            "Prediction:\n",
            " [[-2.7831688]\n",
            " [-2.3010163]\n",
            " [-1.9491172]\n",
            " [-1.542008 ]\n",
            " [-1.8490433]\n",
            " [-1.8159018]\n",
            " [-1.076796 ]\n",
            " [-0.9755857]]\n",
            "34 Cost:  5.992985 \n",
            "Prediction:\n",
            " [[-2.7830436 ]\n",
            " [-2.3008966 ]\n",
            " [-1.9490173 ]\n",
            " [-1.5419307 ]\n",
            " [-1.8489515 ]\n",
            " [-1.8158132 ]\n",
            " [-1.0767374 ]\n",
            " [-0.97552854]]\n",
            "35 Cost:  5.9925327 \n",
            "Prediction:\n",
            " [[-2.7829185]\n",
            " [-2.3007767]\n",
            " [-1.9489174]\n",
            " [-1.5418532]\n",
            " [-1.8488597]\n",
            " [-1.8157246]\n",
            " [-1.0766786]\n",
            " [-0.9754714]]\n",
            "36 Cost:  5.992081 \n",
            "Prediction:\n",
            " [[-2.7827933]\n",
            " [-2.300657 ]\n",
            " [-1.9488174]\n",
            " [-1.5417757]\n",
            " [-1.8487678]\n",
            " [-1.8156359]\n",
            " [-1.07662  ]\n",
            " [-0.9754142]]\n",
            "37 Cost:  5.9916296 \n",
            "Prediction:\n",
            " [[-2.782668  ]\n",
            " [-2.3005373 ]\n",
            " [-1.9487176 ]\n",
            " [-1.5416982 ]\n",
            " [-1.8486761 ]\n",
            " [-1.8155475 ]\n",
            " [-1.0765613 ]\n",
            " [-0.97535706]]\n",
            "38 Cost:  5.9911776 \n",
            "Prediction:\n",
            " [[-2.782543 ]\n",
            " [-2.3004174]\n",
            " [-1.9486177]\n",
            " [-1.541621 ]\n",
            " [-1.8485843]\n",
            " [-1.8154588]\n",
            " [-1.0765026]\n",
            " [-0.9752999]]\n",
            "39 Cost:  5.990726 \n",
            "Prediction:\n",
            " [[-2.7824178 ]\n",
            " [-2.3002975 ]\n",
            " [-1.9485178 ]\n",
            " [-1.5415435 ]\n",
            " [-1.8484925 ]\n",
            " [-1.8153703 ]\n",
            " [-1.0764439 ]\n",
            " [-0.97524273]]\n",
            "40 Cost:  5.9902754 \n",
            "Prediction:\n",
            " [[-2.7822928]\n",
            " [-2.3001778]\n",
            " [-1.9484179]\n",
            " [-1.5414661]\n",
            " [-1.8484006]\n",
            " [-1.8152816]\n",
            " [-1.0763853]\n",
            " [-0.9751856]]\n",
            "41 Cost:  5.9898233 \n",
            "Prediction:\n",
            " [[-2.7821677]\n",
            " [-2.3000581]\n",
            " [-1.948318 ]\n",
            " [-1.5413888]\n",
            " [-1.8483088]\n",
            " [-1.8151932]\n",
            " [-1.0763266]\n",
            " [-0.9751284]]\n",
            "42 Cost:  5.9893713 \n",
            "Prediction:\n",
            " [[-2.7820425]\n",
            " [-2.2999382]\n",
            " [-1.9482181]\n",
            " [-1.5413113]\n",
            " [-1.848217 ]\n",
            " [-1.8151046]\n",
            " [-1.0762678]\n",
            " [-0.9750713]]\n",
            "43 Cost:  5.9889197 \n",
            "Prediction:\n",
            " [[-2.781917  ]\n",
            " [-2.2998185 ]\n",
            " [-1.9481182 ]\n",
            " [-1.5412338 ]\n",
            " [-1.8481252 ]\n",
            " [-1.8150159 ]\n",
            " [-1.0762092 ]\n",
            " [-0.97501415]]\n",
            "44 Cost:  5.988469 \n",
            "Prediction:\n",
            " [[-2.7817922]\n",
            " [-2.2996988]\n",
            " [-1.9480183]\n",
            " [-1.5411564]\n",
            " [-1.8480334]\n",
            " [-1.8149273]\n",
            " [-1.0761505]\n",
            " [-0.974957 ]]\n",
            "45 Cost:  5.9880176 \n",
            "Prediction:\n",
            " [[-2.781667 ]\n",
            " [-2.299579 ]\n",
            " [-1.9479184]\n",
            " [-1.541079 ]\n",
            " [-1.8479416]\n",
            " [-1.8148388]\n",
            " [-1.0760919]\n",
            " [-0.9748998]]\n",
            "46 Cost:  5.987566 \n",
            "Prediction:\n",
            " [[-2.7815418 ]\n",
            " [-2.299459  ]\n",
            " [-1.9478186 ]\n",
            " [-1.5410016 ]\n",
            " [-1.8478498 ]\n",
            " [-1.8147502 ]\n",
            " [-1.0760331 ]\n",
            " [-0.97484267]]\n",
            "47 Cost:  5.9871144 \n",
            "Prediction:\n",
            " [[-2.7814164]\n",
            " [-2.2993395]\n",
            " [-1.9477186]\n",
            " [-1.5409242]\n",
            " [-1.847758 ]\n",
            " [-1.8146616]\n",
            " [-1.0759745]\n",
            " [-0.9747855]]\n",
            "48 Cost:  5.986663 \n",
            "Prediction:\n",
            " [[-2.7812915 ]\n",
            " [-2.2992196 ]\n",
            " [-1.9476188 ]\n",
            " [-1.5408468 ]\n",
            " [-1.8476663 ]\n",
            " [-1.814573  ]\n",
            " [-1.0759158 ]\n",
            " [-0.97472835]]\n",
            "49 Cost:  5.986212 \n",
            "Prediction:\n",
            " [[-2.7811663]\n",
            " [-2.2991   ]\n",
            " [-1.9475188]\n",
            " [-1.5407693]\n",
            " [-1.8475745]\n",
            " [-1.8144846]\n",
            " [-1.0758572]\n",
            " [-0.9746712]]\n",
            "50 Cost:  5.9857607 \n",
            "Prediction:\n",
            " [[-2.7810411 ]\n",
            " [-2.29898   ]\n",
            " [-1.9474192 ]\n",
            " [-1.5406921 ]\n",
            " [-1.8474827 ]\n",
            " [-1.814396  ]\n",
            " [-1.0757985 ]\n",
            " [-0.97461414]]\n",
            "51 Cost:  5.9853096 \n",
            "Prediction:\n",
            " [[-2.780916  ]\n",
            " [-2.2988605 ]\n",
            " [-1.9473193 ]\n",
            " [-1.5406147 ]\n",
            " [-1.8473911 ]\n",
            " [-1.8143075 ]\n",
            " [-1.0757399 ]\n",
            " [-0.97455704]]\n",
            "52 Cost:  5.9848585 \n",
            "Prediction:\n",
            " [[-2.780791  ]\n",
            " [-2.2987406 ]\n",
            " [-1.9472196 ]\n",
            " [-1.5405374 ]\n",
            " [-1.8472993 ]\n",
            " [-1.814219  ]\n",
            " [-1.0756813 ]\n",
            " [-0.97449994]]\n",
            "53 Cost:  5.9844074 \n",
            "Prediction:\n",
            " [[-2.7806659 ]\n",
            " [-2.298621  ]\n",
            " [-1.9471197 ]\n",
            " [-1.5404601 ]\n",
            " [-1.8472077 ]\n",
            " [-1.8141305 ]\n",
            " [-1.0756227 ]\n",
            " [-0.97444284]]\n",
            "54 Cost:  5.983957 \n",
            "Prediction:\n",
            " [[-2.7805407 ]\n",
            " [-2.2985013 ]\n",
            " [-1.9470198 ]\n",
            " [-1.5403826 ]\n",
            " [-1.847116  ]\n",
            " [-1.8140421 ]\n",
            " [-1.075564  ]\n",
            " [-0.97438574]]\n",
            "55 Cost:  5.983506 \n",
            "Prediction:\n",
            " [[-2.7804158 ]\n",
            " [-2.2983816 ]\n",
            " [-1.9469202 ]\n",
            " [-1.5403053 ]\n",
            " [-1.8470242 ]\n",
            " [-1.8139534 ]\n",
            " [-1.0755054 ]\n",
            " [-0.97432864]]\n",
            "56 Cost:  5.9830546 \n",
            "Prediction:\n",
            " [[-2.7802906 ]\n",
            " [-2.298262  ]\n",
            " [-1.9468203 ]\n",
            " [-1.5402279 ]\n",
            " [-1.8469324 ]\n",
            " [-1.813865  ]\n",
            " [-1.0754468 ]\n",
            " [-0.97427154]]\n",
            "57 Cost:  5.982604 \n",
            "Prediction:\n",
            " [[-2.7801657 ]\n",
            " [-2.2981422 ]\n",
            " [-1.9467204 ]\n",
            " [-1.5401506 ]\n",
            " [-1.8468407 ]\n",
            " [-1.8137765 ]\n",
            " [-1.0753882 ]\n",
            " [-0.97421443]]\n",
            "58 Cost:  5.982153 \n",
            "Prediction:\n",
            " [[-2.7800405]\n",
            " [-2.2980225]\n",
            " [-1.9466207]\n",
            " [-1.5400733]\n",
            " [-1.8467491]\n",
            " [-1.813688 ]\n",
            " [-1.0753295]\n",
            " [-0.9741574]]\n",
            "59 Cost:  5.9817023 \n",
            "Prediction:\n",
            " [[-2.7799153]\n",
            " [-2.2979028]\n",
            " [-1.9465208]\n",
            " [-1.5399959]\n",
            " [-1.8466573]\n",
            " [-1.8135996]\n",
            " [-1.075271 ]\n",
            " [-0.9741003]]\n",
            "60 Cost:  5.9812517 \n",
            "Prediction:\n",
            " [[-2.7797904]\n",
            " [-2.2977831]\n",
            " [-1.9464211]\n",
            " [-1.5399187]\n",
            " [-1.8465656]\n",
            " [-1.813511 ]\n",
            " [-1.0752124]\n",
            " [-0.9740432]]\n",
            "61 Cost:  5.9808006 \n",
            "Prediction:\n",
            " [[-2.7796652]\n",
            " [-2.2976635]\n",
            " [-1.9463212]\n",
            " [-1.5398412]\n",
            " [-1.8464739]\n",
            " [-1.8134224]\n",
            " [-1.0751537]\n",
            " [-0.9739861]]\n",
            "62 Cost:  5.9803495 \n",
            "Prediction:\n",
            " [[-2.77954   ]\n",
            " [-2.2975435 ]\n",
            " [-1.9462214 ]\n",
            " [-1.5397639 ]\n",
            " [-1.8463821 ]\n",
            " [-1.813334  ]\n",
            " [-1.0750952 ]\n",
            " [-0.97392905]]\n",
            "63 Cost:  5.9798985 \n",
            "Prediction:\n",
            " [[-2.779415  ]\n",
            " [-2.2974238 ]\n",
            " [-1.9461217 ]\n",
            " [-1.5396866 ]\n",
            " [-1.8462905 ]\n",
            " [-1.8132455 ]\n",
            " [-1.0750365 ]\n",
            " [-0.97387195]]\n",
            "64 Cost:  5.979448 \n",
            "Prediction:\n",
            " [[-2.77929   ]\n",
            " [-2.2973042 ]\n",
            " [-1.9460218 ]\n",
            " [-1.5396092 ]\n",
            " [-1.8461988 ]\n",
            " [-1.8131571 ]\n",
            " [-1.0749779 ]\n",
            " [-0.97381485]]\n",
            "65 Cost:  5.9789977 \n",
            "Prediction:\n",
            " [[-2.779165  ]\n",
            " [-2.2971847 ]\n",
            " [-1.9459219 ]\n",
            " [-1.539532  ]\n",
            " [-1.846107  ]\n",
            " [-1.8130686 ]\n",
            " [-1.0749192 ]\n",
            " [-0.97375774]]\n",
            "66 Cost:  5.978547 \n",
            "Prediction:\n",
            " [[-2.7790399 ]\n",
            " [-2.297065  ]\n",
            " [-1.9458222 ]\n",
            " [-1.5394546 ]\n",
            " [-1.8460152 ]\n",
            " [-1.81298   ]\n",
            " [-1.0748607 ]\n",
            " [-0.97370064]]\n",
            "67 Cost:  5.978096 \n",
            "Prediction:\n",
            " [[-2.7789147]\n",
            " [-2.296945 ]\n",
            " [-1.9457223]\n",
            " [-1.5393772]\n",
            " [-1.8459237]\n",
            " [-1.8128916]\n",
            " [-1.074802 ]\n",
            " [-0.9736436]]\n",
            "68 Cost:  5.9776454 \n",
            "Prediction:\n",
            " [[-2.7787898]\n",
            " [-2.2968254]\n",
            " [-1.9456227]\n",
            " [-1.5393   ]\n",
            " [-1.8458319]\n",
            " [-1.812803 ]\n",
            " [-1.0747435]\n",
            " [-0.9735865]]\n",
            "69 Cost:  5.977194 \n",
            "Prediction:\n",
            " [[-2.7786646]\n",
            " [-2.2967057]\n",
            " [-1.9455228]\n",
            " [-1.5392225]\n",
            " [-1.8457401]\n",
            " [-1.8127146]\n",
            " [-1.0746849]\n",
            " [-0.9735294]]\n",
            "70 Cost:  5.9767447 \n",
            "Prediction:\n",
            " [[-2.7785397]\n",
            " [-2.2965863]\n",
            " [-1.9454231]\n",
            " [-1.5391452]\n",
            " [-1.8456484]\n",
            " [-1.812626 ]\n",
            " [-1.0746262]\n",
            " [-0.9734723]]\n",
            "71 Cost:  5.9762936 \n",
            "Prediction:\n",
            " [[-2.7784145 ]\n",
            " [-2.2964666 ]\n",
            " [-1.9453232 ]\n",
            " [-1.5390679 ]\n",
            " [-1.8455567 ]\n",
            " [-1.8125374 ]\n",
            " [-1.0745676 ]\n",
            " [-0.97341526]]\n",
            "72 Cost:  5.975842 \n",
            "Prediction:\n",
            " [[-2.7782893 ]\n",
            " [-2.2963467 ]\n",
            " [-1.9452233 ]\n",
            " [-1.5389905 ]\n",
            " [-1.8454651 ]\n",
            " [-1.812449  ]\n",
            " [-1.074509  ]\n",
            " [-0.97335815]]\n",
            "73 Cost:  5.9753923 \n",
            "Prediction:\n",
            " [[-2.7781644 ]\n",
            " [-2.2962272 ]\n",
            " [-1.9451237 ]\n",
            " [-1.5389132 ]\n",
            " [-1.8453733 ]\n",
            " [-1.8123605 ]\n",
            " [-1.0744504 ]\n",
            " [-0.97330105]]\n",
            "74 Cost:  5.9749413 \n",
            "Prediction:\n",
            " [[-2.7780392 ]\n",
            " [-2.2961073 ]\n",
            " [-1.9450238 ]\n",
            " [-1.5388359 ]\n",
            " [-1.8452816 ]\n",
            " [-1.8122721 ]\n",
            " [-1.0743918 ]\n",
            " [-0.97324395]]\n",
            "75 Cost:  5.974491 \n",
            "Prediction:\n",
            " [[-2.777914 ]\n",
            " [-2.2959878]\n",
            " [-1.9449241]\n",
            " [-1.5387585]\n",
            " [-1.8451899]\n",
            " [-1.8121836]\n",
            " [-1.0743332]\n",
            " [-0.9731869]]\n",
            "76 Cost:  5.9740405 \n",
            "Prediction:\n",
            " [[-2.777789 ]\n",
            " [-2.2958682]\n",
            " [-1.9448242]\n",
            " [-1.5386813]\n",
            " [-1.8450981]\n",
            " [-1.812095 ]\n",
            " [-1.0742745]\n",
            " [-0.9731298]]\n",
            "77 Cost:  5.9735904 \n",
            "Prediction:\n",
            " [[-2.7776642]\n",
            " [-2.2957485]\n",
            " [-1.9447246]\n",
            " [-1.5386038]\n",
            " [-1.8450065]\n",
            " [-1.8120066]\n",
            " [-1.074216 ]\n",
            " [-0.9730727]]\n",
            "78 Cost:  5.97314 \n",
            "Prediction:\n",
            " [[-2.777539  ]\n",
            " [-2.2956288 ]\n",
            " [-1.9446247 ]\n",
            " [-1.5385265 ]\n",
            " [-1.8449148 ]\n",
            " [-1.811918  ]\n",
            " [-1.0741574 ]\n",
            " [-0.97301567]]\n",
            "79 Cost:  5.9726896 \n",
            "Prediction:\n",
            " [[-2.7774138 ]\n",
            " [-2.295509  ]\n",
            " [-1.944525  ]\n",
            " [-1.5384492 ]\n",
            " [-1.8448231 ]\n",
            " [-1.8118297 ]\n",
            " [-1.0740987 ]\n",
            " [-0.97295856]]\n",
            "80 Cost:  5.972239 \n",
            "Prediction:\n",
            " [[-2.777289  ]\n",
            " [-2.2953894 ]\n",
            " [-1.9444251 ]\n",
            " [-1.5383718 ]\n",
            " [-1.8447313 ]\n",
            " [-1.8117411 ]\n",
            " [-1.0740402 ]\n",
            " [-0.97290146]]\n",
            "81 Cost:  5.9717884 \n",
            "Prediction:\n",
            " [[-2.777164 ]\n",
            " [-2.2952697]\n",
            " [-1.9443252]\n",
            " [-1.5382946]\n",
            " [-1.8446398]\n",
            " [-1.8116527]\n",
            " [-1.0739815]\n",
            " [-0.9728444]]\n",
            "82 Cost:  5.9713383 \n",
            "Prediction:\n",
            " [[-2.7770388]\n",
            " [-2.29515  ]\n",
            " [-1.9442255]\n",
            " [-1.5382172]\n",
            " [-1.844548 ]\n",
            " [-1.8115642]\n",
            " [-1.0739229]\n",
            " [-0.9727873]]\n",
            "83 Cost:  5.9708877 \n",
            "Prediction:\n",
            " [[-2.7769136]\n",
            " [-2.2950304]\n",
            " [-1.9441257]\n",
            " [-1.5381398]\n",
            " [-1.8444562]\n",
            " [-1.8114758]\n",
            " [-1.0738643]\n",
            " [-0.9727302]]\n",
            "84 Cost:  5.9704375 \n",
            "Prediction:\n",
            " [[-2.7767887]\n",
            " [-2.294911 ]\n",
            " [-1.944026 ]\n",
            " [-1.5380626]\n",
            " [-1.8443646]\n",
            " [-1.8113873]\n",
            " [-1.0738058]\n",
            " [-0.9726732]]\n",
            "85 Cost:  5.9699874 \n",
            "Prediction:\n",
            " [[-2.7766638]\n",
            " [-2.2947912]\n",
            " [-1.9439263]\n",
            " [-1.5379853]\n",
            " [-1.844273 ]\n",
            " [-1.8112988]\n",
            " [-1.0737473]\n",
            " [-0.9726162]]\n",
            "86 Cost:  5.9695377 \n",
            "Prediction:\n",
            " [[-2.7765388 ]\n",
            " [-2.2946715 ]\n",
            " [-1.9438267 ]\n",
            " [-1.5379081 ]\n",
            " [-1.8441813 ]\n",
            " [-1.8112104 ]\n",
            " [-1.0736887 ]\n",
            " [-0.97255915]]\n",
            "87 Cost:  5.9690876 \n",
            "Prediction:\n",
            " [[-2.7764137]\n",
            " [-2.294552 ]\n",
            " [-1.9437268]\n",
            " [-1.5378308]\n",
            " [-1.8440897]\n",
            " [-1.8111221]\n",
            " [-1.0736301]\n",
            " [-0.9725022]]\n",
            "88 Cost:  5.9686384 \n",
            "Prediction:\n",
            " [[-2.7762887 ]\n",
            " [-2.2944324 ]\n",
            " [-1.9436272 ]\n",
            " [-1.5377536 ]\n",
            " [-1.8439981 ]\n",
            " [-1.8110337 ]\n",
            " [-1.0735716 ]\n",
            " [-0.97244513]]\n",
            "89 Cost:  5.968188 \n",
            "Prediction:\n",
            " [[-2.7761638 ]\n",
            " [-2.2943127 ]\n",
            " [-1.9435275 ]\n",
            " [-1.5376763 ]\n",
            " [-1.8439064 ]\n",
            " [-1.8109453 ]\n",
            " [-1.073513  ]\n",
            " [-0.97238815]]\n",
            "90 Cost:  5.9677377 \n",
            "Prediction:\n",
            " [[-2.7760386]\n",
            " [-2.2941933]\n",
            " [-1.9434278]\n",
            " [-1.5375991]\n",
            " [-1.8438148]\n",
            " [-1.8108568]\n",
            " [-1.0734545]\n",
            " [-0.9723311]]\n",
            "91 Cost:  5.967287 \n",
            "Prediction:\n",
            " [[-2.7759137 ]\n",
            " [-2.2940736 ]\n",
            " [-1.9433279 ]\n",
            " [-1.5375217 ]\n",
            " [-1.8437232 ]\n",
            " [-1.8107684 ]\n",
            " [-1.073396  ]\n",
            " [-0.97227407]]\n",
            "92 Cost:  5.9668384 \n",
            "Prediction:\n",
            " [[-2.7757888]\n",
            " [-2.2939541]\n",
            " [-1.9432284]\n",
            " [-1.5374445]\n",
            " [-1.8436315]\n",
            " [-1.8106799]\n",
            " [-1.0733374]\n",
            " [-0.9722171]]\n",
            "93 Cost:  5.966388 \n",
            "Prediction:\n",
            " [[-2.7756639 ]\n",
            " [-2.2938344 ]\n",
            " [-1.9431286 ]\n",
            " [-1.5373672 ]\n",
            " [-1.84354   ]\n",
            " [-1.8105915 ]\n",
            " [-1.0732789 ]\n",
            " [-0.97216004]]\n",
            "94 Cost:  5.9659386 \n",
            "Prediction:\n",
            " [[-2.775539 ]\n",
            " [-2.2937148]\n",
            " [-1.9430289]\n",
            " [-1.53729  ]\n",
            " [-1.8434483]\n",
            " [-1.8105031]\n",
            " [-1.0732204]\n",
            " [-0.972103 ]]\n",
            "95 Cost:  5.9654884 \n",
            "Prediction:\n",
            " [[-2.7754138]\n",
            " [-2.2935953]\n",
            " [-1.942929 ]\n",
            " [-1.5372126]\n",
            " [-1.8433567]\n",
            " [-1.8104147]\n",
            " [-1.0731618]\n",
            " [-0.972046 ]]\n",
            "96 Cost:  5.9650383 \n",
            "Prediction:\n",
            " [[-2.7752888]\n",
            " [-2.2934756]\n",
            " [-1.9428295]\n",
            " [-1.5371354]\n",
            " [-1.843265 ]\n",
            " [-1.8103263]\n",
            " [-1.0731032]\n",
            " [-0.971989 ]]\n",
            "97 Cost:  5.9645886 \n",
            "Prediction:\n",
            " [[-2.775164 ]\n",
            " [-2.293356 ]\n",
            " [-1.9427297]\n",
            " [-1.5370581]\n",
            " [-1.8431735]\n",
            " [-1.8102379]\n",
            " [-1.0730447]\n",
            " [-0.971932 ]]\n",
            "98 Cost:  5.964139 \n",
            "Prediction:\n",
            " [[-2.7750387 ]\n",
            " [-2.2932365 ]\n",
            " [-1.94263   ]\n",
            " [-1.5369809 ]\n",
            " [-1.8430817 ]\n",
            " [-1.8101494 ]\n",
            " [-1.0729861 ]\n",
            " [-0.97187495]]\n",
            "99 Cost:  5.9636893 \n",
            "Prediction:\n",
            " [[-2.7749138]\n",
            " [-2.2931168]\n",
            " [-1.9425304]\n",
            " [-1.5369036]\n",
            " [-1.8429902]\n",
            " [-1.810061 ]\n",
            " [-1.0729276]\n",
            " [-0.971818 ]]\n",
            "100 Cost:  5.963239 \n",
            "Prediction:\n",
            " [[-2.7747889]\n",
            " [-2.2929974]\n",
            " [-1.9424306]\n",
            " [-1.5368264]\n",
            " [-1.8428986]\n",
            " [-1.8099726]\n",
            " [-1.0728691]\n",
            " [-0.9717609]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkavXX-Hh68c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}